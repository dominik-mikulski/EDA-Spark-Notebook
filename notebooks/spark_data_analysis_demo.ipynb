{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64a200ce-852f-44d1-9997-9db039bef82b",
   "metadata": {},
   "source": [
    "# Spark Data Analysis Demo\n",
    "This notebook is a demo of how you one can use spark for exploratory data analysis.stems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f209f4-6098-4b6f-9df2-717f997eeb18",
   "metadata": {},
   "source": [
    "## 1. Why this EDA exists\r\n",
    "\r\n",
    "In modern data platforms, data constantly crosses system boundaries:\r\n",
    "from applications to data distributors, from distributors to data lakes,\r\n",
    "from data lakes to warehouses, and from warehouses into analytics\r\n",
    "and machine-learning systems.\r\n",
    "\r\n",
    "At each of these transitions, data can become incomplete\r\n",
    "(e.g. broken exports), duplicative (e.g. repeated ingestimistreatednderstood (e.g. timestamps ingested as strings, numbers parsed as text).\r\n",
    "These issues often propagate silently and eventually break reports,\r\n",
    "analytics, and machine-learning models.\r\n",
    "\r\n",
    "This EDA exissuch detect those risks early, before the data is used\r\n",
    "in product\n",
    "\n",
    "This EDA does not cover ingestion errors (i.e. corrupted files or transmissions), it assumes data parsing completed without errors. ion pipelines. silent data corruption.\r\n",
    " be automated in production pipelines.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8b3588b-5baf-430b-b2ec-b7d42291eb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To explore data we need a spark session. Its and an object used to read data, explore data (including not limited to sql), access spark confirguration. \n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"spark-dq-demo\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aaae1640-fec2-4548-b2a0-6b3d11f96b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets read a csv file into spark data frame, inferSchema will detect datatypes (if consistent), header will take first row as header.\n",
    "df = spark.read.csv(\n",
    "    \"../data/retail_personalization_dataset.csv\",\n",
    "    inferSchema=True,\n",
    "    header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3356488-1f3a-4bea-866e-694828746a16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- product_id: string (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- session_id: string (nullable = true)\n",
      " |-- interaction_type: string (nullable = true)\n",
      " |-- device_type: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- discount: integer (nullable = true)\n",
      " |-- product_category: string (nullable = true)\n",
      " |-- brand: string (nullable = true)\n",
      " |-- user_age: integer (nullable = true)\n",
      " |-- user_gender: string (nullable = true)\n",
      " |-- loyalty_score: integer (nullable = true)\n",
      " |-- previous_purchase_count: integer (nullable = true)\n",
      " |-- avg_purchase_value: double (nullable = true)\n",
      " |-- search_keywords: string (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- purchase: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# let's print schema of the data frame\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74da27a-6e9d-494e-a389-ab55dffde2a9",
   "metadata": {},
   "source": [
    "Because the source is a CSV file, there is no enforced schema or\r\n",
    "nullability contract, and all constraints must be validated in Spark.\r\n",
    "\r\n",
    "Headers were read correctly and key fields such as timestamp, price,\r\n",
    "discount, user_age, loyalty_score, previous_purchase_count,\r\n",
    "avg_purchase_value, rating, and purchase were correctly inferred as\r\n",
    "numeric or temporal types and not silently downgraded to strings due to\r\n",
    "inconsistent formatting.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13e87df9-a164-4450-848a-5583f05cde36",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
